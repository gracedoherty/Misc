{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0190f8",
   "metadata": {},
   "source": [
    "## 0. PSEUDOCODE / OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca727bc7",
   "metadata": {},
   "source": [
    "##### Before this script:\n",
    "Summed the MapSPAM crop rasters for each year. Code is available at:\n",
    "<br> https://github.com/gracedoherty/Misc/blob/main/MapSPAM%20batch%20sums.ipynb\n",
    "\n",
    "<br> Manually renamed the Value of Production rasters from 2005 and 2010 to match naming conventions of the rest. (The VoP files for these years did not need to be summed in the previous script and still had their MapSPAM source file names.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9093fd6",
   "metadata": {},
   "source": [
    "##### Prep data\n",
    "Reproject MapSPAM to equal area.\n",
    "\n",
    "##### Mask to area of interest\n",
    "Because we are using the clunky tif-xyz-df-gdf zonal stats method, it will reduce processing time to first mask out pixels not in the region of interest.\n",
    "\n",
    "##### Zonal statistics\n",
    "Aggregation method: sum.\n",
    "\n",
    "##### Change over time\n",
    "Calculate the percent change in agro indicators between the four years of study (2000,2005,2010,2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba808a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9276b447",
   "metadata": {},
   "source": [
    "## 1. PREPARE WORKSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a2548",
   "metadata": {},
   "source": [
    "### 1.1 Load all packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in:\n",
    "# dir(), print(), range(), format(), int(), len(), list(), max(), min(), zip(), sorted(), sum(), open(), del, = None, try except, with as, for in, if elif else\n",
    "# Also: list.append(), list.insert(), list.remove(), count(), startswith(), endswith(), contains(), replace()\n",
    "\n",
    "import os, sys, glob, re, time, subprocess, string # os.getcwd(), os.path.join(), os.listdir(), os.remove(), time.ctime(), glob.glob(), string.zfill(), string.join()\n",
    "from os.path import exists # exists()\n",
    "from functools import reduce # reduce()\n",
    "\n",
    "import geopandas as gpd # read_file(), GeoDataFrame(), sjoin_nearest(), to_crs(), to_file(), .crs, buffer(), dissolve()\n",
    "import pandas as pd # .dtypes, Series(), concat(), DataFrame(), read_table(), merge(), to_csv(), .loc[], head(), sample(), astype(), unique(), rename(), between(), drop(), fillna(), idxmax(), isna(), isin(), apply(), info(), sort_values(), notna(), groupby(), value_counts(), duplicated(), drop_duplicates()\n",
    "from shapely.geometry import Point, LineString, Polygon, shape, MultiPoint\n",
    "from shapely.ops import cascaded_union\n",
    "from shapely.validation import make_valid  # in apply(make_valid)\n",
    "import shapely.wkt\n",
    "\n",
    "import numpy as np # median(), mean(), tolist(), .inf\n",
    "import fiona, rioxarray # fiona.open()\n",
    "import rasterio # open(), write_band(), .name, .count, .width, .height. nodatavals, .meta, update(), copy(), write()\n",
    "from rasterio.plot import show\n",
    "from rasterio import features # features.rasterize()\n",
    "from rasterio.features import shapes\n",
    "from rasterio import mask # rasterio.mask.mask()\n",
    "from rasterio.enums import Resampling # rasterio.enums.Resampling()\n",
    "from osgeo import gdal, osr, ogr, gdal_array, gdalconst # Open(), SpatialReference, WarpOptions(), Warp(), GetDataTypeName(), GetRasterBand(), GetNoDataValue(), Translate(), GetProjection(), GetAttrValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c74225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\Agriculture\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\LivelihoodZones_forPython\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\LivelihoodZones_forPython\\LZ.gpkg\n"
     ]
    }
   ],
   "source": [
    "ProjectFolder = os.getcwd()\n",
    "print(ProjectFolder)\n",
    "\n",
    "LZFolder = 'Q:\\GIS\\povertyequity\\PTI_Sahel\\LivelihoodZones_forPython'\n",
    "print(LZFolder)\n",
    "\n",
    "LZPath = os.path.join(LZFolder, 'LZ.gpkg')\n",
    "print(LZPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5f9d7",
   "metadata": {},
   "source": [
    "### 1.2 User-defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679884ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677821a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rioStats(InRasterPath, Band = 1):\n",
    "    out = rasterio.open(InRasterPath)\n",
    "    stats = []\n",
    "    band = out.read(Band)\n",
    "    stats.append({\n",
    "        'raster': out.name,\n",
    "        'bands': out.count,\n",
    "        'data type': out.dtypes,\n",
    "        'no data value': out.nodatavals,\n",
    "        'width': out.width,\n",
    "        'height': out.height,\n",
    "        'min': band.min(),\n",
    "        'mean': band.mean(),\n",
    "        'median': np.median(band),\n",
    "        'max': band.max()})\n",
    "    print(\"\\n\", stats)\n",
    "    \n",
    "    out = band = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca96f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaskByZone(MaskPath, SourceFolder, DestFolder, SourceList = None,\n",
    "               MaskLayerName = None, dstSRS = 'ESRI:102022'):\n",
    "    \"\"\"\n",
    "    Reduces the size of a raster's valid data cells to vector areas of interest.\n",
    "    This is useful if the raster data needs to be vectorized later to save space.\n",
    "    \n",
    "    The script prepares the vector zones as a list of geometries in the desired\n",
    "    spatial reference system, then warps each raster in the specified source\n",
    "    folder to the same SRS. Masking in rasterio then reclassifies any raster cells\n",
    "    falling outside of a mask polygon as NoData.\n",
    "    \"\"\"\n",
    "    \n",
    "    ProjSRS = osr.SpatialReference()\n",
    "    ProjSRS.SetFromUserInput(dstSRS)\n",
    "    ProjWarp = gdal.WarpOptions(dstSRS = dstSRS)\n",
    "    \n",
    "    if SourceList is not None:\n",
    "        SourceFiles = SourceList\n",
    "    else:\n",
    "        SourceFiles = []\n",
    "        SourceFiles = SourceFiles + [i for i in os.listdir(''.join([SourceFolder, r'/'])) if i.endswith('tif')]\n",
    "        print(SourceFiles)\n",
    "\n",
    "    \n",
    "    ### 1. ASSIGN SPATIAL REFERENCE SYSTEM OF VECTOR MASK AND LOAD GEOMETRIES\n",
    "    Vector = gpd.read_file(filename=MaskPath, layer=MaskLayerName)\n",
    "    if Vector.crs != dstSRS:\n",
    "        if MaskLayerName == None:\n",
    "            MaskPath = MaskPath + '_temp'\n",
    "        else:\n",
    "            MaskLayerName = MaskLayerName + '_temp'\n",
    "        Vector.to_crs(dstSRS).to_file(filename=MaskPath, layer=MaskLayerName)\n",
    "    Vector = None # We're reloading the geometries with fiona\n",
    "    \n",
    "    with fiona.open(MaskPath, mode=\"r\", layer=MaskLayerName) as Vector:\n",
    "        MaskGeom = [feature[\"geometry\"] for feature in Vector] # Identify the bounding areas of the mask.\n",
    "    \n",
    "    \n",
    "    ### 2. PREPARE DESTINATION FILES\n",
    "    for FileName in SourceFiles:\n",
    "    \n",
    "        InputRasterPath = os.path.join(ProjectFolder, SourceFolder, FileName)\n",
    "\n",
    "        TempOutputName = 'Temp_' + FileName\n",
    "        TempOutputPath = os.path.join(ProjectFolder, DestFolder, TempOutputName)\n",
    "        FinalOutputName = 'Msk_' + FileName\n",
    "        FinalOutputPath = os.path.join(ProjectFolder, DestFolder, FinalOutputName)\n",
    "\n",
    "    ### 3. ASSIGN SPATIAL REFERENCE SYSTEM OF RASTER(S)\n",
    "        InputRasterObject = gdal.Open(InputRasterPath)\n",
    "        SourceSRS = osr.SpatialReference(wkt=InputRasterObject.GetProjection())\n",
    "        print('Source projection: ', SourceSRS.GetAttrValue('projcs'))\n",
    "        print('Destination projection: ', ProjSRS.GetAttrValue('projcs'))\n",
    "\n",
    "        if SourceSRS.GetAttrValue('projcs') != ProjSRS.GetAttrValue('projcs'):\n",
    "            Warp = gdal.Warp(TempOutputPath, # Where to store the warped raster\n",
    "                         InputRasterObject, # Which raster to warp\n",
    "                         format='GTiff', \n",
    "                         options=ProjWarp) # Reproject to Africa Albers Equal Area Conic\n",
    "            print('Finished gdal.Warp() for %s. %s \\n' % (FileName, time.ctime()))\n",
    "\n",
    "            Warp = None # Close the files\n",
    "        else:\n",
    "            pass\n",
    "        InputRasterObject = None\n",
    "        \n",
    "    ### 4. RECLASSIFY AS NODATA IF OUTSIDE OF SETTLEMENT BUFFER ZONE.\n",
    "        if exists(TempOutputPath):\n",
    "            NewInputPath = TempOutputPath \n",
    "            print(\"We warped the data, so we'll use that file for next step.\")\n",
    "        else:\n",
    "            NewInputPath = InputRasterPath \n",
    "            print(\"We skipped the warp, so we continue to use the source file.\")\n",
    "\n",
    "        with rasterio.open(NewInputPath) as InputRasterObject:\n",
    "            MaskedOutputRaster, OutTransform = rasterio.mask.mask(\n",
    "                InputRasterObject, MaskGeom, crop=True) # Anything outside the mask is reclassed to the raster's NoData value.\n",
    "            OutMetaData = InputRasterObject.meta.copy()\n",
    "        print('Finished rasterio.mask.mask() for %s. %s \\n' % (FileName, time.ctime()))\n",
    "\n",
    "        OutMetaData.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": MaskedOutputRaster.shape[1],\n",
    "                         \"width\": MaskedOutputRaster.shape[2],\n",
    "                         \"transform\": OutTransform})\n",
    "\n",
    "        with rasterio.open(FinalOutputPath, \"w\", **OutMetaData) as dest:\n",
    "            dest.write(MaskedOutputRaster)\n",
    "        print('Written to file. %s \\n' % time.ctime())\n",
    "        InputRasterObject = None\n",
    "\n",
    "        if exists(TempOutputPath):\n",
    "            try:  # Finally, remove the intermediate file from disk\n",
    "                os.remove(TempOutputPath)\n",
    "            except OSError:\n",
    "                pass\n",
    "            print('Removed intermediate file. %s \\n' % time.ctime())\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    print('\\n \\n Finished all years in list. %s' % time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6a43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchZonalStats(FolderName, Zones, \n",
    "                    CRS = 'ESRI:102022', \n",
    "                    JoinField = 'Sett_ID',\n",
    "                    StatsWanted = ['count', 'sum', 'mean', 'max', 'min'],\n",
    "                    SeriesStart = 1999, SeriesEnd = 2015, \n",
    "                    AnnualizedFiles = None, VarPrefix = None):\n",
    "    \"\"\"\n",
    "    Normally, we would use numpy to generate a point gdf from the raster's matrix. \n",
    "    However, I was running into a lot of memory errors with that method.\n",
    "    This method uses some extra steps: tif to xyz to df to gdf. But it saves to file\n",
    "    and deletes intermediate files along the way, circumventing memory issues.\n",
    "    \n",
    "    Run MaskByZone() prior to reduce the raster to only your area(s) of interest.\n",
    "    \n",
    "    \"\"\"\n",
    "    if AnnualizedFiles is None:\n",
    "        AnnualizedFiles = [i for i in os.listdir(FolderName) if i.endswith('.tif')]\n",
    "    print(AnnualizedFiles)\n",
    "    AllSummaries = pd.DataFrame(Zones).drop(columns='geometry')[[JoinField]]\n",
    "    print(AllSummaries)\n",
    "    \n",
    "    if VarPrefix is None:\n",
    "        VarPrefix = FolderName[:3].upper()\n",
    "    \n",
    "    for FileName in AnnualizedFiles:\n",
    "    ### STEP 1: TIF TO XYZ ###\n",
    "        print('Loading data for %s. %s \\n' % (FileName, time.ctime()))\n",
    "        \n",
    "        InputRasterPath = os.path.join(ProjectFolder, FolderName, FileName)\n",
    "        InputRasterObject = gdal.Open(InputRasterPath)\n",
    "        XYZOutputPath = FolderName + r'/{}'.format(\n",
    "            FileName.replace('.tif', '.xyz')) # New file path will be the same as original, but .tif is replaced with .xyz\n",
    "\n",
    "        # Create an .xyz version of the .tif\n",
    "        if exists(XYZOutputPath):\n",
    "            print(\"Already created xyz file.\")\n",
    "        else:\n",
    "            print(\"Creating XYZ (gdal.Translate()).\")\n",
    "            XYZ = gdal.Translate(XYZOutputPath, # Specify a destination path\n",
    "                                 InputRasterObject, # Input is the masked .tif file\n",
    "                                 format='XYZ', \n",
    "                                 creationOptions=[\"ADD_HEADER_LINE=YES\"])\n",
    "            print('Finished gdal.Translate() for year %s. %s \\n' % (Year, time.ctime()))\n",
    "            XYZ = None # Reload XYZ as a point geodataframe\n",
    "\n",
    "        InputRasterObject = None\n",
    "\n",
    "\n",
    "    ### STEP 2: GENERATE GEODATAFRAME WITH JOIN FIELD ###\n",
    "        InputXYZ = pd.read_table(XYZOutputPath, delim_whitespace=True)\n",
    "        InputXYZ = InputXYZ.loc[InputXYZ['Z'] > -1] # Subset to only the features that have a value.\n",
    "            \n",
    "        print('Loaded XYZ file as a pandas dataframe. %s \\n' % time.ctime())\n",
    "        ValObject = gpd.GeoDataFrame(InputXYZ,\n",
    "                                     geometry = gpd.points_from_xy(InputXYZ['X'], InputXYZ['Y']),\n",
    "                                     crs = CRS)\n",
    "        print('Created geodataframe from non-NoData points. %s \\n' % time.ctime())\n",
    "        del InputXYZ\n",
    "\n",
    "        # Sjoin_nearest: No need to group by ADM this time. \n",
    "        ValObject_withID = pd.DataFrame(gpd.sjoin_nearest(ValObject, \n",
    "                                        Zones, \n",
    "                                        how='left')).drop(columns='geometry')[['Z', JoinField]] # No need for max_distance parameter this time. We've already narrowed down to nearby raster cells.\n",
    "\n",
    "        print('\\nJoined zone ID onto vectorized raster cells. %s \\n' % time.ctime())\n",
    "        print(ValObject_withID.sample(10))\n",
    "        del ValObject\n",
    "\n",
    "        ValObject_withID.to_csv(''.join([FolderName, r'/', FileName.replace('.tif', '.csv')]))\n",
    "        print('\\nExported as table. %s \\n' % time.ctime())\n",
    "\n",
    "\n",
    "    ### STEP 3: AGGREGATE BY SETTLEMENT AND MERGE ONTO SUMMARIES TABLE ###\n",
    "        GroupedVals = ValObject_withID[ValObject_withID['Z'].notna()].groupby(JoinField, as_index=False)\n",
    "        \n",
    "        # Run this block if the variable is about cloud-free coverage.\n",
    "        if re.search('cfc', FileName) is not None:\n",
    "            VariableName = ''.join([VarPrefix, 'cfc_', Sensor, Year])\n",
    "            AllSummaries = AllSummaries.merge(GroupedVals.mean().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            print('\\nCount of cloud-free observations averaged to settlement level, year %s. %s \\n' % (Year, time.ctime()))\n",
    "            \n",
    "            # Save in-progress results\n",
    "            AllSummaries.to_csv(os.path.join(ResultsFolder, ''.join([VarPrefix, '%sto%s.csv' % (SeriesStart, SeriesEnd)])))\n",
    "            print(AllSummaries.sample(10))\n",
    "        \n",
    "        # Run this block if we're working with the flooded buildings data.\n",
    "        elif re.search('WSFE', FileName) is not None:\n",
    "            for BuiltYear in AllStudyYears:\n",
    "                Grouped_Subset = GroupedVals[GroupedVals['Z'].between(\n",
    "                    1985, BuiltYear, inclusive=True)] # Inclusive parameter means we include the years 1985 and the named year.\n",
    "                if 'count' in StatsWanted:\n",
    "                    VariableName = ''.join([VarPrefix, 'ct', Sensor, BuiltYear])\n",
    "                    AllSummaries = AllSummaries.merge(GroupedVals.count().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "                if 'sum' in StatsWanted:\n",
    "                    VariableName = ''.join([VarPrefix, 'sum', Sensor, BuiltYear])\n",
    "                    AllSummaries = AllSummaries.merge(GroupedVals.sum().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "                if 'mean' in StatsWanted:\n",
    "                    VariableName = ''.join([VarPrefix, 'avg', Sensor, BuiltYear])\n",
    "                    AllSummaries = AllSummaries.merge(GroupedVals.mean().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "                if 'max' in StatsWanted:\n",
    "                    VariableName = ''.join([VarPrefix, 'max', Sensor, BuiltYear])\n",
    "                    AllSummaries = AllSummaries.merge(GroupedVals.max().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "                if 'min' in StatsWanted:\n",
    "                    VariableName = ''.join([VarPrefix, 'min', Sensor, BuiltYear])\n",
    "                    AllSummaries = AllSummaries.merge(GroupedVals.min().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "                print('\\nDesired aggregation methods applied to settlement level, year %s. %s \\n' % (Year, time.ctime()))\n",
    "\n",
    "                # Save in-progress results\n",
    "                AllSummaries.to_csv(os.path.join(ResultsFolder, ''.join([VarPrefix, '%sto%s.csv' % (SeriesStart, SeriesEnd)])))\n",
    "                print(AllSummaries.sample(10))\n",
    "        \n",
    "        # Anything else takes the standard aggregation method.\n",
    "        else:\n",
    "            if 'count' in StatsWanted:\n",
    "                VariableName = ''.join([VarPrefix, 'ct', Sensor, Year])\n",
    "                AllSummaries = AllSummaries.merge(GroupedVals.count().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            if 'sum' in StatsWanted:\n",
    "                VariableName = ''.join([VarPrefix, 'sum', Sensor, Year])\n",
    "                AllSummaries = AllSummaries.merge(GroupedVals.sum().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            if 'mean' in StatsWanted:\n",
    "                VariableName = ''.join([VarPrefix, 'avg', Sensor, Year])\n",
    "                AllSummaries = AllSummaries.merge(GroupedVals.mean().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            if 'max' in StatsWanted:\n",
    "                VariableName = ''.join([VarPrefix, 'max', Sensor, Year])\n",
    "                AllSummaries = AllSummaries.merge(GroupedVals.max().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            if 'min' in StatsWanted:\n",
    "                VariableName = ''.join([VarPrefix, 'min', Sensor, Year])\n",
    "                AllSummaries = AllSummaries.merge(GroupedVals.min().rename(columns={'Z': VariableName}), how = 'left', on=JoinField)\n",
    "            print('\\nDesired aggregation methods applied to settlement level, year %s. %s \\n' % (Year, time.ctime()))\n",
    "            \n",
    "            # Save in-progress results\n",
    "            AllSummaries.to_csv(os.path.join(ResultsFolder, ''.join([VarPrefix, '%sto%s.csv' % (SeriesStart, SeriesEnd)])))\n",
    "            print(AllSummaries.sample(10))\n",
    "\n",
    "    \n",
    "    print('\\n\\nFinished. All years masked and assigned their nearest settlement. %s' % time.ctime())\n",
    "    print(AllSummaries.sample(10))\n",
    "    AllSummaries.to_csv(os.path.join(ResultsFolder, ''.join([VarPrefix, '%sto%s.csv' % (SeriesStart, SeriesEnd)])))\n",
    "    print('Saved to file. %s \\n' % time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bf6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc7320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26fd55d6",
   "metadata": {},
   "source": [
    "## 2. LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb8502",
   "metadata": {},
   "source": [
    "##### ADMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a98a05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1433 entries, 0 to 1432\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   admin3Name  1433 non-null   object  \n",
      " 1   admin3Pcod  1433 non-null   object  \n",
      " 2   admin2Pcod  1433 non-null   object  \n",
      " 3   admin1Pcod  1433 non-null   object  \n",
      " 4   admin0Pcod  1433 non-null   object  \n",
      " 5   ADM3_CODE   1433 non-null   object  \n",
      " 6   ADM2_CODE   1433 non-null   object  \n",
      " 7   ADM1_CODE   1433 non-null   object  \n",
      " 8   geometry    1433 non-null   geometry\n",
      " 9   FID         1433 non-null   int64   \n",
      "dtypes: geometry(1), int64(1), object(8)\n",
      "memory usage: 112.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# The ADMs in the LZ.gpkg are already in our preferred projection.\n",
    "ADM3, ADM2, ADM1 = gpd.read_file(LZPath, layer='ADM3'), gpd.read_file(LZPath, layer='ADM2'), gpd.read_file(LZPath, layer='ADM1')\n",
    "ADM3['FID'], ADM2['FID'], ADM1['FID'] = ADM3.index, ADM2.index, ADM1.index\n",
    "ADM3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63001223",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMlist = [ADM1, ADM2, ADM3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97f94f",
   "metadata": {},
   "source": [
    "##### Agro rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1681af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarvArea_2000_allTech.tif',\n",
       " 'HarvArea_2000_Irrigated.tif',\n",
       " 'HarvArea_2005_allTech.tif',\n",
       " 'HarvArea_2005_Irrigated.tif',\n",
       " 'HarvArea_2010_allTech.tif',\n",
       " 'HarvArea_2010_Irrigated.tif',\n",
       " 'HarvArea_2017_allTech.tif',\n",
       " 'HarvArea_2017_Irrigated.tif',\n",
       " 'PhysArea_2000_allTech.tif',\n",
       " 'PhysArea_2000_Irrigated.tif',\n",
       " 'PhysArea_2005_allTech.tif',\n",
       " 'PhysArea_2005_Irrigated.tif',\n",
       " 'PhysArea_2010_allTech.tif',\n",
       " 'PhysArea_2010_Irrigated.tif',\n",
       " 'PhysArea_2017_allTech.tif',\n",
       " 'PhysArea_2017_Irrigated.tif',\n",
       " 'Val_2005_allTech.tif',\n",
       " 'Val_2005_Irrigated.tif',\n",
       " 'Val_2010_allTech.tif',\n",
       " 'Val_2010_Irrigated.tif',\n",
       " 'Val_2017_allTech.tif',\n",
       " 'Val_2017_Irrigated.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SourceFiles = []\n",
    "SourceFiles = SourceFiles + [i for i in os.listdir('Global_Agro_Sums') if i.endswith('tif')]\n",
    "SourceFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3f474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "997cc854",
   "metadata": {},
   "source": [
    "## 3. MASK TO AREA OF INTEREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8903f",
   "metadata": {},
   "source": [
    "This also reprojects anything that needs to be into the preferred spatial reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for File in SourceFiles:\n",
    "#     inRaster = gdal.Open(os.path.join('Global_Agro_Sums', File))\n",
    "#     outPath = os.path.join('IntermediateFiles', File.replace('.tif', 'EqArea.tif'))\n",
    "#     warp = gdal.Warp(outPath,inRaster,dstSRS='ESRI:102022')\n",
    "#     warp = None # Closes the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7070ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaskByZone(MaskPath=LZPath, SourceFolder, DestFolder='IntermediateFiles', \n",
    "           SourceList = SourceFiles, MaskLayerName = 'ADM1', dstSRS = 'ESRI:102022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce42a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f7e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "679f843f",
   "metadata": {},
   "source": [
    "## 4. ZONAL STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1a354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb8771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
