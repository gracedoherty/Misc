{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0190f8",
   "metadata": {},
   "source": [
    "## 0. PSEUDOCODE / OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9093fd6",
   "metadata": {},
   "source": [
    "##### Prep data\n",
    "Merge countries' hazard impact vectors into one gdf.\n",
    "\n",
    "##### Spatial join to project ADMs\n",
    "Get centroids of hazard gdf.\n",
    "<br> For each ADM, spatial join ADM with centroids (contains).\n",
    "\n",
    "##### Combine into dataframe\n",
    "Provide unique field names.\n",
    "<br> Table join on ADM3 code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276b447",
   "metadata": {},
   "source": [
    "## 1. PREPARE WORKSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a2548",
   "metadata": {},
   "source": [
    "### 1.1 Load all packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in:\n",
    "# dir(), print(), range(), format(), int(), len(), list(), max(), min(), zip(), sorted(), sum(), open(), del, = None, try except, with as, for in, if elif else\n",
    "# Also: list.append(), list.insert(), list.remove(), count(), startswith(), endswith(), contains(), replace()\n",
    "\n",
    "import os, sys, glob, re, time, subprocess, string # os.getcwd(), os.path.join(), os.listdir(), os.remove(), time.ctime(), glob.glob(), string.zfill(), string.join()\n",
    "from os.path import exists # exists()\n",
    "from functools import reduce # reduce()\n",
    "\n",
    "import geopandas as gpd # read_file(), GeoDataFrame(), sjoin_nearest(), to_crs(), to_file(), .crs, buffer(), dissolve()\n",
    "import pandas as pd # .dtypes, Series(), concat(), DataFrame(), read_table(), merge(), to_csv(), .loc[], head(), sample(), astype(), unique(), rename(), between(), drop(), fillna(), idxmax(), isna(), isin(), apply(), info(), sort_values(), notna(), groupby(), value_counts(), duplicated(), drop_duplicates()\n",
    "from shapely.geometry import Point, LineString, Polygon, shape, MultiPoint\n",
    "from shapely.ops import cascaded_union\n",
    "from shapely.validation import make_valid  # in apply(make_valid)\n",
    "import shapely.wkt\n",
    "\n",
    "import numpy as np # median(), mean(), tolist(), .inf\n",
    "import fiona, rioxarray # fiona.open()\n",
    "import rasterio # open(), write_band(), .name, .count, .width, .height. nodatavals, .meta, update(), copy(), write()\n",
    "from rasterio.plot import show\n",
    "from rasterio import features # features.rasterize()\n",
    "from rasterio.features import shapes\n",
    "from rasterio import mask # rasterio.mask.mask()\n",
    "from rasterio.enums import Resampling # rasterio.enums.Resampling()\n",
    "from rasterstats import zonal_stats\n",
    "from osgeo import gdal, osr, ogr, gdal_array, gdalconst # Open(), SpatialReference, WarpOptions(), Warp(), GetDataTypeName(), GetRasterBand(), GetNoDataValue(), Translate(), GetProjection(), GetAttrValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c74225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\GIS\\povertyequity\\PTI_Sahel\n",
      "\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\Hazard\n",
      "\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\Hazard\\Source\\2022\n",
      "\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\Hazard\\Intermediate\n",
      "\n",
      "Q:\\GIS\\povertyequity\\CCDR\n",
      "\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\ADM\n",
      "\n",
      "Q:\\GIS\\povertyequity\\PTI_Sahel\\ADM\\Sahel_AdminBoundaries.gpkg\n"
     ]
    }
   ],
   "source": [
    "# The usual directories\n",
    "Project_Fd = os.getcwd()\n",
    "Current_Fd = os.path.join(Project_Fd, 'Hazard')\n",
    "Source_Fd = os.path.join(Current_Fd, 'Source', '2022')\n",
    "Intermed_Fd = os.path.join(Current_Fd, 'Intermediate')\n",
    "\n",
    "# Auxilliary sources\n",
    "ADM_Fd = os.path.join(Project_Fd, 'ADM')\n",
    "ADM_gpkg = os.path.join(ADM_Fd, 'Sahel_AdminBoundaries.gpkg')\n",
    "CCDR_Fd = 'Q:\\GIS\\povertyequity\\CCDR'\n",
    "\n",
    "# Check paths\n",
    "print('\\n\\n'.join([Project_Fd, Current_Fd, Source_Fd, Intermed_Fd, CCDR_Fd, ADM_Fd, ADM_gpkg]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6aab87",
   "metadata": {},
   "source": [
    "## 2. PREP ADMIN LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8580938",
   "metadata": {},
   "source": [
    "### 2.1 CCDR-to-PTI dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff128020",
   "metadata": {},
   "source": [
    "Note: this dictionary was made manually in QGIS based on admin boundary alignments between the incongruent admin area datasets.\n",
    "\n",
    "CCDR admin area count: (remember that one country is missing in each admin set)\n",
    "<br>ADM2: 182\n",
    "<br>ADM3: 1329\n",
    "\n",
    "PTI admin area count:\n",
    "<br>ADM2: 275\n",
    "<br>ADM3: 1433"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2611ac3",
   "metadata": {},
   "source": [
    "#### CCDR-PTI dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08419bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182 entries, 0 to 181\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CCDR       182 non-null    int64 \n",
      " 1   ADM2_CODE  182 non-null    object\n",
      " 2   ADM2_s2    23 non-null     object\n",
      " 3   ADM2_s3    7 non-null      object\n",
      " 4   ADM2_s4    2 non-null      object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 7.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1329 entries, 0 to 1328\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   CCDR       1329 non-null   float64\n",
      " 1   ADM3_CODE  1329 non-null   object \n",
      " 2   ADM3_s2    4 non-null      object \n",
      " 3   ADM3_s3    1 non-null      object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 41.7+ KB\n",
      "None None \n",
      "\n",
      "      CCDR ADM2_CODE ADM2_s2 ADM2_s3 ADM2_s4\n",
      "70   5002    NE0502    None    None    None\n",
      "158  1601    TD1601  TD1604    None    None\n",
      "4    4601    BF0201    None    None    None\n",
      "3    5402    BF1002    None    None    None\n",
      "50   6013    NE0613    None    None    None\n",
      "100  2001    NE0201    None    None    None\n",
      "138   904    TD0901    None    None    None\n",
      "118   303    TD0302    None    None    None\n",
      "170  2202    TD2202  TD2203    None    None\n",
      "90   7006    NE0706    None    None    None \n",
      "\n",
      "            CCDR ADM3_CODE ADM3_s2 ADM3_s3\n",
      "1110  6010002.0  NE061003    None    None\n",
      "250    560308.0  BF120308    None    None\n",
      "524     50609.0  ML060608    None    None\n",
      "314    500307.0  BF060307    None    None\n",
      "1246  7007007.0  NE070705    None    None\n",
      "578     60405.0  ML090404    None    None\n",
      "639     20207.0  ML050214    None    None\n",
      "622     10616.0  ML030603    None    None\n",
      "152    460404.0  BF020404    None    None\n",
      "867     80203.0  ML040203    None    None\n"
     ]
    }
   ],
   "source": [
    "CCDR_ADM2 = pd.DataFrame(gpd.read_file(\n",
    "    os.path.join(Intermed_Fd, 'CCDR_ADM2_consolidated.shp')))[['CCDR', 'ADM2_CODE', 'ADM2_s2', 'ADM2_s3', 'ADM2_s4']]\n",
    "\n",
    "CCDR_ADM3 = pd.DataFrame(gpd.read_file(\n",
    "    os.path.join(Intermed_Fd, 'CCDR_ADM3_consolidated.shp')))[['CCDR', 'ADM3_CODE', 'ADM3_s2', 'ADM3_s3']]\n",
    "\n",
    "print(CCDR_ADM2.info(), CCDR_ADM3.info(), '\\n\\n', CCDR_ADM2.sample(10), '\\n\\n', CCDR_ADM3.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35183c",
   "metadata": {},
   "source": [
    "#### Pivot longer: ADM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cf175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCDR</th>\n",
       "      <th>PTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5503</td>\n",
       "      <td>BF1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4803</td>\n",
       "      <td>BF0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5603</td>\n",
       "      <td>BF1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5402</td>\n",
       "      <td>BF1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4601</td>\n",
       "      <td>BF0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2101</td>\n",
       "      <td>TD2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2201</td>\n",
       "      <td>TD2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2301</td>\n",
       "      <td>TD2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>2101</td>\n",
       "      <td>TD2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2301</td>\n",
       "      <td>TD2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CCDR     PTI\n",
       "0    5503  BF1103\n",
       "1    4803  BF0403\n",
       "2    5603  BF1203\n",
       "3    5402  BF1002\n",
       "4    4601  BF0201\n",
       "..    ...     ...\n",
       "531  2101  TD2103\n",
       "533  2201  TD2201\n",
       "535  2301  TD2004\n",
       "713  2101  TD2104\n",
       "717  2301  TD2003\n",
       "\n",
       "[214 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_ADM2 = pd.melt(CCDR_ADM2, id_vars=['CCDR'], value_vars=[col for col in CCDR_ADM2 if col.startswith('ADM2')], \n",
    "                    value_name='PTI')\n",
    "Dict_ADM2 = Dict_ADM2.loc[Dict_ADM2['PTI'].notnull()][['CCDR', 'PTI']]\n",
    "Dict_ADM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d559938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PTI polygons associated with more than one CCDR polygon:  41\n",
      "Number of CCDR polygons associated with more than one PTI polygon:  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of PTI polygons associated with more than one CCDR polygon: ', \n",
    "      (len(Dict_ADM2.index.unique()) - len(Dict_ADM2['CCDR'].unique())))\n",
    "print('Number of CCDR polygons associated with more than one PTI polygon: ', \n",
    "      (len(Dict_ADM2.index.unique()) - len(Dict_ADM2['PTI'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58b79c",
   "metadata": {},
   "source": [
    "#### Pivot longer: ADM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409c9905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCDR</th>\n",
       "      <th>PTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550301.0</td>\n",
       "      <td>BF110301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480301.0</td>\n",
       "      <td>BF040301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>560301.0</td>\n",
       "      <td>BF120301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540201.0</td>\n",
       "      <td>BF100201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540202.0</td>\n",
       "      <td>BF100202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>60301.0</td>\n",
       "      <td>ML090401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>80401.0</td>\n",
       "      <td>ML040402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>100301.0</td>\n",
       "      <td>ML020403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>70307.0</td>\n",
       "      <td>ML020304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>80401.0</td>\n",
       "      <td>ML040403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CCDR       PTI\n",
       "0     550301.0  BF110301\n",
       "1     480301.0  BF040301\n",
       "2     560301.0  BF120301\n",
       "3     540201.0  BF100201\n",
       "4     540202.0  BF100202\n",
       "...        ...       ...\n",
       "2179   60301.0  ML090401\n",
       "2199   80401.0  ML040402\n",
       "2266  100301.0  ML020403\n",
       "2275   70307.0  ML020304\n",
       "3528   80401.0  ML040403\n",
       "\n",
       "[1334 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_ADM3 = pd.melt(CCDR_ADM3, id_vars=['CCDR'], value_vars=[col for col in CCDR_ADM3 if col.startswith('ADM3')], \n",
    "                    value_name='PTI')\n",
    "Dict_ADM3 = Dict_ADM3.loc[Dict_ADM3['PTI'].notnull()][['CCDR', 'PTI']]\n",
    "Dict_ADM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99238cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PTI polygons associated with more than one CCDR polygon:  16\n",
      "Number of CCDR polygons associated with more than one PTI polygon:  20\n"
     ]
    }
   ],
   "source": [
    "print('Number of PTI polygons associated with more than one CCDR polygon: ', \n",
    "      (len(Dict_ADM3.index.unique()) - len(Dict_ADM3['CCDR'].unique())))\n",
    "print('Number of CCDR polygons associated with more than one PTI polygon: ', \n",
    "      (len(Dict_ADM3.index.unique()) - len(Dict_ADM3['PTI'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054585b",
   "metadata": {},
   "source": [
    "## 2. PREP RISK DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236fab2",
   "metadata": {},
   "source": [
    "### 2.1 Clean up risk layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd06cee",
   "metadata": {},
   "source": [
    "#### Load all indicators as separate ADM2 and ADM3 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "BFA_ADM2 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"BFA*ADM2*\"))]\n",
    "NER_ADM2 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"NER*ADM2*\"))]\n",
    "TCD_ADM2 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"TCD*ADM2*\"))]\n",
    "\n",
    "BFA_ADM3 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"BFA*ADM3*\"))]\n",
    "MLI_ADM3 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"MLI*ADM3*\"))]\n",
    "NER_ADM3 = [pd.DataFrame(gpd.read_file(f, layer=os.path.basename(f).replace('.gpkg', ''))).drop(columns='geometry') \n",
    "            for f in glob.glob(os.path.join(Source_Fd, \"NER*ADM3*\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(BFA_ADM2), len(BFA_ADM3))\n",
    "print(len(MLI_ADM3))\n",
    "print(len(NER_ADM2), len(NER_ADM3))\n",
    "print(len(TCD_ADM2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc14c653",
   "metadata": {},
   "source": [
    "#### Drought and flood have some inconsistent naming. Rename to match before concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04247aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropADM = ['ADM0_CODE', 'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'ADM2_NAME', 'ADM3_NAME']\n",
    "\n",
    "ListofLists = [BFA_ADM2, NER_ADM2, TCD_ADM2, BFA_ADM3, MLI_ADM3, NER_ADM3]\n",
    "\n",
    "for dfList in ListofLists:\n",
    "    i = 0\n",
    "    for df in dfList:\n",
    "        if 'S1_30_mean' in df.columns:\n",
    "            dfList[i] = df.rename(columns={'S1_30_mean':'S1_30p_mean'})\n",
    "        if 'S1_50_mean' in df.columns:\n",
    "            dfList[i] = df.rename(columns={'S1_50_mean':'S1_50p_mean'})\n",
    "        if 'EAE' in df.columns:\n",
    "            dfList[i] = df.rename(columns={'EAE':'EAE_agri'})\n",
    "            \n",
    "            \n",
    "        # Let's also remove the extra admin areas while we're at it. Otherwise the pd.concat() function will have trouble.\n",
    "        try:\n",
    "            dfList[i] = df.drop(columns=df.columns.intersection(dropADM), axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        if 'ADM3_CODE' in df.columns:\n",
    "            try:\n",
    "                dfList[i] = df.drop(columns='ADM2_CODE', axis=1) # If the df is ADM3 features, drop the ADM2 code.\n",
    "            except:\n",
    "                pass\n",
    "        print(dfList[i].info())\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496540ea",
   "metadata": {},
   "source": [
    "### 2.2 Merge and concatenate indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88187f99",
   "metadata": {},
   "source": [
    "#### Merge indicators of same country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged = []\n",
    "for dfList in ListofLists:\n",
    "    Merged = Merged + [pd.concat(dfList, axis=1).reset_index()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa32c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Merged[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72972ca",
   "metadata": {},
   "source": [
    "#### Concatenate countries together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ac0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indic_A2 = pd.concat(Merged[0:2], axis=1)\n",
    "Indic_A3 = pd.concat(Merged[3:5], axis=1)\n",
    "Indic_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98040b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indic_A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591087eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTI and CCDR admin fields are the same label. Changing to distinguish from one another.\n",
    "Indic_A2 = Indic_A2.rename(columns={'ADM2_CODE':'CCDR'})\n",
    "Indic_A3 = Indic_A3.rename(columns={'ADM3_CODE':'CCDR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141ccaa",
   "metadata": {},
   "source": [
    "### 2.2 Merge with CCDR ADMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCDR2 = CCDR_ADM2[['CCDR']].merge(Indic_A2, how='left', on='CCDR')\n",
    "CCDR3 = CCDR_ADM3[['CCDR']].merge(Indic_A3, how='left', on='CCDR')\n",
    "\n",
    "print(CCDR2.info(), CCDR2.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424e38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indic3 = FL_ADM3 + [CCDR_ADM3] + HS_ADM3 + DR_ADM3 + LS_ADM3\n",
    "CCDR3 = \n",
    "CCDR3 = pd.concat(Indic3, axis=1)\n",
    "CCDR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6177c932",
   "metadata": {},
   "source": [
    "#### Concatenate each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc28d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "HZ_A2 = {'DR':pd.concat(DR_ADM2, ignore_index=True), \n",
    "         'HS':pd.concat(HS_ADM2, ignore_index=True), \n",
    "         'FL':pd.concat(FL_ADM2, ignore_index=True),\n",
    "         'LS':pd.concat(LS_ADM2, ignore_index=True)}\n",
    "for k in HZ_A2:\n",
    "    HZ_A2[k] = HZ_A2[k].rename(columns={'ADM2_CODE':'CCDR'}) # Rename admin area field to match CCDR-PTI dictionary.\n",
    "    print('\\n\\n', k + \": \", HZ_A2[k]['ADM0_NAME'].unique())\n",
    "    print('\\n\\n', HZ_A2[k].info(), '\\n\\n', HZ_A2[k].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab23e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "HZ_A3 = {'DR':pd.concat(DR_ADM3, ignore_index=True), \n",
    "         'HS':pd.concat(HS_ADM3, ignore_index=True), \n",
    "         'FL':pd.concat(FL_ADM3, ignore_index=True),\n",
    "         'LS':pd.concat(LS_ADM3, ignore_index=True)}\n",
    "for k in HZ_A3:\n",
    "    HZ_A3[k] = HZ_A3[k].rename(columns={'ADM3_CODE':'CCDR'})\n",
    "    print('\\n\\n', k + \": \", HZ_A3[k]['ADM0_NAME'].unique())\n",
    "    print('\\n\\n', HZ_A3[k].info(), '\\n\\n', HZ_A3[k].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925ec8a",
   "metadata": {},
   "source": [
    "#### Remove unnecessary fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove excess variables.\n",
    "Indicators = ['S1_30p_mean', 'S1_50p_mean', # DR\n",
    "              'EAE_C4', 'EAE_C4%', # HS\n",
    "              'builtup_EAI', 'builtup_EAI%', 'pop_EAI', 'pop_EAI%', 'EAE_agri', # FL\n",
    "              'builtup_tot_exposed', 'pop_tot_exposed' # LS\n",
    "              ]\n",
    "\n",
    "Fields = Indicators + ['CCDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f8ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Indic_A2 = HZ_A2.copy()\n",
    "Indic_A3 = HZ_A3.copy()\n",
    "\n",
    "# Overwrite the values in the dictionary with the updated, smaller dfs.\n",
    "for k in HZ_A2:\n",
    "    Indic_A2[k] = HZ_A2[k][HZ_A2[k].columns.intersection(Fields)]\n",
    "for k in HZ_A3:\n",
    "    Indic_A3[k] = HZ_A3[k][HZ_A3[k].columns.intersection(Fields)]\n",
    "\n",
    "Indic_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69aa0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Indic_A3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483e913",
   "metadata": {},
   "source": [
    "#### Rename fields to include hazard type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5cf987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in Indic_A2:\n",
    "    Indic_A2[k].columns = [k + '_' + col if col in Indicators else col for col in Indic_A2[k].columns]\n",
    "Indic_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599accd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in Indic_A3:\n",
    "    Indic_A3[k].columns = [k + '_' + col if col in Indicators else col for col in Indic_A3[k].columns]\n",
    "Indic_A3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6a671",
   "metadata": {},
   "source": [
    "### 2.2 Merge risk indicators by CCDR ADM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2593da8",
   "metadata": {},
   "source": [
    "#### Merge indicators into one df per ADM type now that hazard indicators have unique labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43718765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need for dictionary keys anymore. Let's simplify.\n",
    "Indic_A2 = list(Indic_A2.values())\n",
    "Indic_A3 = list(Indic_A3.values())\n",
    "print(len(Indic_A2), len(Indic_A3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried doing this as a for loop (for k, prevk in zip()), but was struggling.\n",
    "Indic_ADM2 = Indic_A2[0].merge(Indic_A2[1], on='CCDR', how='outer')\n",
    "Indic_ADM2 = Indic_ADM2.merge(Indic_A2[2], on='CCDR', how='outer')\n",
    "Indic_ADM2 = Indic_ADM2.merge(Indic_A2[3], on='CCDR', how='outer')\n",
    "\n",
    "Indic_ADM3 = Indic_A3[0].merge(Indic_A3[1], on='CCDR', how='outer')\n",
    "Indic_ADM3 = Indic_ADM3.merge(Indic_A3[2], on='CCDR', how='outer')\n",
    "Indic_ADM3 = Indic_ADM3.merge(Indic_A3[3], on='CCDR', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03b24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Indic_ADM2.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f636f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Indic_ADM3.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3e441",
   "metadata": {},
   "source": [
    "## 4. MATCH RISK INDICATORS WITH PTI ADMIN AREAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c79c1",
   "metadata": {},
   "source": [
    "### 4.1 Categorize indicators by eligible aggregation or disaggregation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d1ebd",
   "metadata": {},
   "source": [
    "If splitting a hazard ADM into 2+ project ADMs, AND if indicator does not depend on the polygon size or amount (intensive):\n",
    "<br> Indicator unchanged, applied to each ADM.\n",
    "\n",
    "If splitting a hazard ADM into 2+ project ADMs, AND if indicator is dependent on the polygon size or amount (extensive):\n",
    "<br> No data applied to each ADM.\n",
    "\n",
    "If dissolving 2+ hazard ADMs into a project ADM, AND if indicator is intensive:\n",
    "<br> No data applied to each ADM.\n",
    "\n",
    "If dissolving 2+ hazard ADMs into a project ADM, AND if indicator is extensive:\n",
    "<br> -- If indicator is count, apply sum.\n",
    "<br> -- If indicator is average, apply no data.\n",
    "<br> -- If indicator is max, apply max."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f6b8b",
   "metadata": {},
   "source": [
    "Drought percent: INTENSIVE, AVERAGE\n",
    "- If >1 CCDR to a PTI, no data.\n",
    "- If >1 PTI to a CCDR, orig value.\n",
    "\n",
    "Landslide: EXTENSIVE, COUNT\n",
    "- If >1 CCDR to a PTI, sum.\n",
    "- If >1 PTI to a CCDR, no data. \n",
    "\n",
    "Flood: EXTENSIVE, COUNT\n",
    "- If >1 CCDR to a PTI, sum.\n",
    "- If >1 PTI to a CCDR, no data.\n",
    "\n",
    "Flood percent: INTENSIVE, PROPORTION\n",
    "- If >1 CCDR to a PTI, no data.\n",
    "- If >1 PTI to a CCDR, orig value.\n",
    "\n",
    "Heat stress: EXTENSIVE, COUNT\n",
    "- If >1 CCDR to a PTI, sum.\n",
    "- If >1 PTI to a CCDR, no data.\n",
    "\n",
    "Heat stress percent: INTENSIVE, PROPORTION\n",
    "- If >1 CCDR to a PTI, no data.\n",
    "- If >1 PTI to a CCDR, orig value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67abbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Indic_ADM2.info(), '\\n', Indic_ADM3.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the Indicators list and assign intensive or extensive.\n",
    "Intensive = ['DR_S1_30p_mean', 'DR_S1_50p_mean', # DR\n",
    "              'HS_EAE_C4%', # HS\n",
    "              'FL_builtup_EAI%', 'FL_pop_EAI%' # FL\n",
    "              # LS\n",
    "            ]\n",
    "\n",
    "Extensive = [# DR\n",
    "              'HS_EAE_C4', # HS\n",
    "              'FL_builtup_EAI', 'FL_pop_EAI', 'FL_EAE_agri', # FL\n",
    "              'LS_builtup_tot_exposed', 'LS_pop_tot_exposed' # LS\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fa644",
   "metadata": {},
   "source": [
    "### 4.2 Group-by aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3f0f5",
   "metadata": {},
   "source": [
    "#### Table join risk indicators onto project ADMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f5270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ADM2 = CCDR_ADM2.merge(Indic_ADM2, on='CCDR', how='left')\n",
    "ADM3 = CCDR_ADM3.merge(Indic_ADM3, on='CCDR', how='left')\n",
    "print(ADM2.info(), ADM3.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74aae8c",
   "metadata": {},
   "source": [
    "#### Identify duplicates and mark them in the expanded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5aab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset rows that have duplicate PTI ADM: dupePTI\n",
    "dupePTI_A2 = ADM2[ADM2.duplicated(['ADM2_CODE'], keep='first')]\n",
    "dupePTI_A2 = list(dupePTI_A2['ADM2_CODE'])\n",
    "\n",
    "dupePTI_A3 = ADM3[ADM3.duplicated(['ADM3_CODE'], keep='first')]\n",
    "dupePTI_A3 = list(dupePTI_A3['ADM3_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset rows that have duplicate CCDR ADM: dupeCCDR\n",
    "dupeCCDR_A2 = ADM2[ADM2.duplicated(['CCDR'], keep='first')]\n",
    "dupeCCDR_A2 = list(dupeCCDR_A2['CCDR'])\n",
    "\n",
    "dupeCCDR_A3 = ADM3[ADM3.duplicated(['CCDR'], keep='first')]\n",
    "dupeCCDR_A3 = list(dupeCCDR_A3['CCDR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74f48d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ADM2['dupeCCDR'] = 0 # Default value will be zero\n",
    "ADM2['dupePTI'] = 0\n",
    "ADM2.loc[ADM2.CCDR.isin(dupeCCDR_A2), 'dupeCCDR'] = 1\n",
    "ADM2.loc[ADM2.ADM2_CODE.isin(dupePTI_A2), 'dupePTI'] = 1\n",
    "\n",
    "ADM3['dupeCCDR'] = 0\n",
    "ADM3['dupePTI'] = 0\n",
    "ADM3.loc[ADM3.CCDR.isin(dupeCCDR_A3), 'dupeCCDR'] = 1\n",
    "ADM3.loc[ADM3.ADM3_CODE.isin(dupePTI_A3), 'dupePTI'] = 1\n",
    "\n",
    "print(ADM2.sample(10), ADM3.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e5bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check to make sure there are 2 unique values for the dupe fields.\n",
    "print(ADM2.nunique(axis=0), ADM3.nunique(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop CCDR ADM field now\n",
    "ADM2 = ADM2.drop(columns='CCDR', axis=1)\n",
    "ADM3 = ADM3.drop(columns='CCDR', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674642b1",
   "metadata": {},
   "source": [
    "#### Group-by PTI ADMs and apply appropriate aggregation or null setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038311b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can work with just the PTI ADM features.\n",
    "ADM2_Int = ADM2.drop(columns=Extensive).groupby(\n",
    "    'ADM2_CODE', as_index=False).first() # Keep original value\n",
    "\n",
    "ADM2_Ext = ADM2.drop(columns=Intensive).groupby(\n",
    "    'ADM2_CODE', as_index=False).sum() # Sum these counts\n",
    "ADM2_Int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM3_Int = ADM3.drop(columns=Extensive).groupby(\n",
    "    'ADM3_CODE', as_index=False).first() # Keep original value\n",
    "\n",
    "ADM3_Ext = ADM3.drop(columns=Intensive).groupby(\n",
    "    'ADM3_CODE', as_index=False).sum() # Sum these counts\n",
    "ADM3_Int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change extensive variables to None if there were multiple PTI ADMs\n",
    "for col in Extensive:\n",
    "    ADM2_Ext.loc[ADM2_Ext.dupePTI > 0, col] = None\n",
    "# Change intensive variables to None if there were multiple CCDR ADMs\n",
    "for col in Intensive:\n",
    "    ADM2_Int.loc[ADM2_Int.dupeCCDR > 0, col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Extensive:\n",
    "    ADM3_Ext.loc[ADM3_Ext.dupePTI > 0, col] = None\n",
    "for col in Intensive:\n",
    "    ADM3_Int.loc[ADM3_Int.dupeCCDR > 0, col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge intensive and extensive variables into single df and save to file.\n",
    "ADM2_PTI = ADM2_Int.merge(ADM2_Ext, on='ADM2_CODE', how='outer')\n",
    "ADM2_PTI = ADM2_PTI.loc[:, ~ADM2_PTI.columns.str.contains('dupe')]\n",
    "ADM3_PTI = ADM3_Int.merge(ADM3_Ext, on='ADM3_CODE', how='outer')\n",
    "ADM3_PTI = ADM3_PTI.loc[:, ~ADM3_PTI.columns.str.contains('dupe')]\n",
    "print(ADM2_PTI.info(), ADM3_PTI.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43395b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM2_PTI.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM3_PTI.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a09b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd6e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5f93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3eb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1359e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dea0b90",
   "metadata": {},
   "source": [
    "### 2.1 Concatenate countries' CCDR admin areas into a parent object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd304d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FileNames_ADM2 = [''.join([ISO, '_FL_ADM2_pop_EAI']) for ISO in ['BFA', 'NER', 'TCD']]\n",
    "FileNames_ADM3 = [''.join([ISO, '_FL_ADM3_pop_EAI']) for ISO in ['BFA', 'MLI', 'NER']]\n",
    "\n",
    "# ADM2\n",
    "CCDR_ADM2 = [gpd.read_file(os.path.join(Source_Fd, ''.join([FileName, '.gpkg'])), layer=FileName, driver='GPKG') for FileName in FileNames_ADM2]\n",
    "\n",
    "# ADM3\n",
    "CCDR_ADM3 = [gpd.read_file(os.path.join(Source_Fd, ''.join([FileName, '.gpkg'])), layer=FileName, driver='GPKG') for FileName in FileNames_ADM3]\n",
    "\n",
    "print([Item.info() for Item in CCDR_ADM2], [Item.info() for Item in CCDR_ADM3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db972d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Match all projections for concatenation.')\n",
    "for prevf, f in zip(CCDR_ADM2, CCDR_ADM2[1:]):\n",
    "    print('Checking...')\n",
    "    if f.crs != prevf.crs:\n",
    "        try:\n",
    "            f.to_crs(prevf.crs)\n",
    "            print('Reprojecting to match previous.')\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print('Matches with previous.')\n",
    "        \n",
    "print('\\n\\nFinal CRS list:')\n",
    "for f in CCDR_ADM2:\n",
    "    print(f.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Match all projections for concatenation.')\n",
    "for prevf, f in zip(CCDR_ADM3, CCDR_ADM3[1:]):\n",
    "    print('Checking...')\n",
    "    if f.crs != prevf.crs:\n",
    "        try:\n",
    "            f.to_crs(prevf.crs)\n",
    "            print('Reprojecting to match previous.')\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print('Matches with previous.')\n",
    "        \n",
    "print('\\n\\nFinal CRS list:')\n",
    "for f in CCDR_ADM3:\n",
    "    print(f.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979681e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CCDR_A2 = pd.concat(CCDR_ADM2, ignore_index=True)\n",
    "print(CCDR_A2.info(), '\\n\\n', CCDR_A2['ADM0_NAME'].unique(), '\\n\\n', CCDR_A2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d9abd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CCDR_A3 = pd.concat(CCDR_ADM3, ignore_index=True)\n",
    "print(CCDR_A3.info(), '\\n\\n', CCDR_A3['ADM0_NAME'].unique(), '\\n\\n', CCDR_A3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2234a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop excess variables and rename the ADM codes since their names are identical to the PTI.\n",
    "CCDR_A2 = CCDR_A2[['ADM0_CODE', 'ADM2_CODE', 'geometry']]\n",
    "CCDR_A2 = CCDR_A2.rename(columns={'ADM0_CODE':'ISO', 'ADM2_CODE':'ADM2_CCDR'})\n",
    "\n",
    "CCDR_A3 = CCDR_A3[['ADM0_CODE', 'ADM3_CODE', 'geometry']]\n",
    "CCDR_A3 = CCDR_A3.rename(columns={'ADM0_CODE':'ISO', 'ADM3_CODE':'ADM3_CCDR'})\n",
    "\n",
    "print(CCDR_A2.info(), CCDR_A3.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
